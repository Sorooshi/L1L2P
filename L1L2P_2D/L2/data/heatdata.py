from data.split_data import split_into_time_series, lang_list
from data.heatmap import draw_heatmap, draw_scatter

import tensorflow as tf

from typing import List, Dict, Any, Tuple
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import cv2
import io

wh_list = [75, 100, 200]
img_data_types = ['gauss', 'scatter', 'dot']
methods = ['clf', 'reg']


def fig_to_np(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    buf.seek(0)
    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)
    buf.close()
    img = cv2.imdecode(img_arr, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (180, 60), interpolation=cv2.INTER_LINEAR)
    img[0, :] = img[img.shape[0] - 1, :] = img[:, 0] = img[:, img.shape[1] - 1] = 0
    plt.close(fig)
    return img


def get_gauss_data(data, wh=100):
    X, y, demo = split_into_time_series(data, truncate=False, test_size=0)
    X_x = [np.array(t['Fix_X'].values) for t in X]
    X_y = [np.array(t['Fix_Y'].values) for t in X]
    X_dur = [np.array(t['Fix_Duration'].values) for t in X]

    X_img = np.zeros((len(X), 60, 180))
    for i in range(len(X)):
        X_img[i, :, :] = fig_to_np(draw_heatmap(X_x[i], X_y[i], X_dur[i], gaussian_wh=wh))

    return X_img, y, demo


def get_scatter_data(data):
    X, y, demo = split_into_time_series(data, truncate=False, test_size=0)
    X_x = [np.array(t['Fix_X'].values) for t in X]
    X_y = [np.array(t['Fix_Y'].values) for t in X]
    X_dur = [np.array(t['Fix_Duration'].values) for t in X]

    X_img = np.zeros((len(X), 60, 180))
    for i in range(len(X)):
        X_img[i, :, :] = fig_to_np(draw_scatter(X_x[i], X_y[i], X_dur[i])).T
    return X_img, y, demo


def load_gauss(lang_names: List[str], wh: List[int], path_to_data: str = 'Data/gauss') \
        -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Loads images generated by applying Gaussian blur to eye movement hotspots.

    :param lang_names: list of languages to be used in the test
    :param wh: the width-height of the Gaussian blurring window
    :param path_to_data: the location of the dataset relative to the current directory
    :return: data split into images, labels and demographic information
    """
    wh = int(wh[0])
    assert wh in wh_list

    X, y, demo = np.load(f'{path_to_data}/{lang_names.pop(0)}_wh{wh}.npz', allow_pickle=True).values()
    for lang in lang_names:
        X_, y_, demo_ = np.load(f'{path_to_data}/{lang}_wh{wh}.npz', allow_pickle=True).values()
        X = np.append(X, X_, axis=0)
        y = np.append(y, y_, axis=0)
        demo = np.append(demo, demo_, axis=0)
    return X, y, demo


def load_scatter(lang_names: List[str], path_to_data: str = 'Data/scatter') \
        -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Loads images representing eye movement data with scatter plots.

    :param lang_names: list of languages to be used in the test
    :param path_to_data: the location of the dataset relative to the current directory
    :return: data split into images, labels and demographic information
    """
    X, y, demo = np.load(f'{path_to_data}/{lang_names.pop(0)}.npz', allow_pickle=True).values()
    for lang in lang_names:
        X_, y_, demo_ = np.load(f'{path_to_data}/{lang}.npz', allow_pickle=True).values()
        X = np.append(X, X_, axis=0)
        y = np.append(y, y_, axis=0)
        demo = np.append(demo, demo_, axis=0)
    return X, y, demo


def load_dot(lang_names: List[str], path_to_data: str = 'Data/dot') \
        -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Loads images representing eye movement data with dot plots.

    :param lang_names: list of languages to be used in the test
    :param path_to_data: the location of the dataset relative to the current directory
    :return: data split into images, labels and demographic information
    """
    X, y, demo = np.load(f'{path_to_data}/{lang_names.pop(0)}.npz', allow_pickle=True).values()
    for lang in lang_names:
        X_, y_, demo_ = np.load(f'{path_to_data}/{lang}.npz', allow_pickle=True).values()
        X = np.append(X, X_, axis=0)
        y = np.append(y, y_, axis=0)
        demo = np.append(demo, demo_, axis=0)
    return X, y, demo


def make_img_dataset(lang_names: List[str], data_type: str, params: Dict[str, Any] = None,
                     method='clf', path_to_data: str = 'Data') \
        -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Creates a dataset of numpy images with specified parameters

    :param lang_names: list of languages to be used in the test
    :param data_type: the type of data to be used in the test
    :param params: extra parameters for choosing data for the test
    :param method: determines whether to run classification or regression
    :param path_to_data: the location of the dataset relative to the current directory
    :return: tuple of numpy images, labels/target values and demographic data
    """
    assert all(lang in lang_list for lang in lang_names), f'you entered an inexistent language'
    assert data_type in img_data_types, f'{data_type} data type doesn\'t exist'

    if data_type == 'gauss':
        X, y, demo = load_gauss(lang_names, **params, path_to_data=f'{path_to_data}/gauss')
    elif data_type == 'scatter':
        X, y, demo = load_scatter(lang_names, path_to_data=f'{path_to_data}/scatter')
    elif data_type == 'dot':
        X, y, demo = load_dot(lang_names, path_to_data=f'{path_to_data}/dot')

    X = X[:, :, :, tf.newaxis]
    X /= 255.0
    if method == 'clf':
        y, _ = pd.factorize(demo[:, 2])
    return X, y, demo
